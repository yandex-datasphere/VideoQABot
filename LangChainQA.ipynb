{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "052f40f0",
   "metadata": {
    "cellId": "yzdzyw1o8ujhmnrk4xly6m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/89/b2/3b74b85356662637bfe3efbc6462ccb28227215fcf8e07b5e9a830f5c661/langchain-0.0.275-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.0.275-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting sentence_transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lancedb\n",
      "  Obtaining dependency information for lancedb from https://files.pythonhosted.org/packages/0b/59/8800508af2c0afe0269278432ed5a7a8b03bebc75826ac211ee4053bf7a1/lancedb-0.2.2-py3-none-any.whl.metadata\n",
      "  Downloading lancedb-0.2.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting unstructured\n",
      "  Obtaining dependency information for unstructured from https://files.pythonhosted.org/packages/e3/97/478e5f01e8922acc140ee35adde4c5e6861f7a693fe57daafe53947e6602/unstructured-0.10.8-py3-none-any.whl.metadata\n",
      "  Downloading unstructured-0.10.8-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
      "  Obtaining dependency information for dataclasses-json<0.6.0,>=0.5.7 from https://files.pythonhosted.org/packages/97/5f/e7cc90f36152810cab08b6c9c1125e8bcb9d76f8b3018d101b5f877b386c/dataclasses_json-0.5.14-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.21 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.21 from https://files.pythonhosted.org/packages/2b/cb/3525fb0d1bf144840c726345a107ad35998565a05e99d4bfec755c71ffd8/langsmith-0.0.27-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.27-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
      "Collecting transformers<5.0.0,>=4.6.0 (from sentence_transformers)\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.6.0 from https://files.pythonhosted.org/packages/83/8d/f65f8138365462ace54458a9e164f4b28ce1141361970190eef36bdef986/transformers-4.32.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.32.1-py3-none-any.whl.metadata (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.2+cu118)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.10.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
      "Collecting sentencepiece (from sentence_transformers)\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence_transformers)\n",
      "  Obtaining dependency information for huggingface-hub>=0.4.0 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pylance==0.6.5 (from lancedb)\n",
      "  Obtaining dependency information for pylance==0.6.5 from https://files.pythonhosted.org/packages/bf/71/acaace11900627025b64efac1b6496755b4000ec335837ed3940616d6e3f/pylance-0.6.5-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pylance-0.6.5-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting ratelimiter (from lancedb)\n",
      "  Downloading ratelimiter-1.2.0.post0-py3-none-any.whl (6.6 kB)\n",
      "Collecting retry (from lancedb)\n",
      "  Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
      "Collecting attr (from lancedb)\n",
      "  Downloading attr-0.3.2-py2.py3-none-any.whl (3.3 kB)\n",
      "Collecting semver>=3.0 (from lancedb)\n",
      "  Obtaining dependency information for semver>=3.0 from https://files.pythonhosted.org/packages/d4/5d/f2b4fe45886238c405ad177ca43911cb1459d08003004da5c27495eb4216/semver-3.0.1-py3-none-any.whl.metadata\n",
      "  Downloading semver-3.0.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting pyarrow>=10 (from pylance==0.6.5->lancedb)\n",
      "  Obtaining dependency information for pyarrow>=10 from https://files.pythonhosted.org/packages/a1/14/4ffed5e85b96f0c0ae9e026f940bf71ac7dfbfbffff9f3fe339e32bfce2c/pyarrow-13.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading pyarrow-13.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.0.0)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.3)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /kernel/lib/python3.10/site-packages (from unstructured) (4.12.2)\n",
      "Collecting emoji (from unstructured)\n",
      "  Obtaining dependency information for emoji from https://files.pythonhosted.org/packages/96/c6/0114b2040a96561fd1b44c75df749bbd3c898bf8047fb5ce8d7590d2dee6/emoji-2.8.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading emoji-2.8.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /kernel/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /kernel/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /kernel/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (20.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Collecting charset-normalizer<4.0,>=2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /kernel/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (16.0.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/6c/f0/c17bbdb1e5f9dab29d44cade445135789f75f8f08ea2728d04493ea8412b/safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /kernel/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.4.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.6)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.1)\n",
      "Requirement already satisfied: decorator>=3.4.2 in /kernel/lib/python3.10/site-packages (from retry->lancedb) (5.1.1)\n",
      "Collecting py<2.0.0,>=1.4.26 (from retry->lancedb)\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /kernel/lib/python3.10/site-packages (from torchvision->sentence_transformers) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /kernel/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (2.4.7)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /kernel/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "Downloading langchain-0.0.275-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lancedb-0.2.2-py3-none-any.whl (35 kB)\n",
      "Downloading pylance-0.6.5-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading unstructured-0.10.8-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
      "Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.0.27-py3-none-any.whl (34 kB)\n",
      "Downloading semver-3.0.1-py3-none-any.whl (17 kB)\n",
      "Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-13.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Building wheels for collected packages: sentence_transformers\n",
      "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125915 sha256=4c76632795f0e26c6c36b45c4873e663e45b682df7a8d8cb7d02049af212a587\n",
      "  Stored in directory: /tmp/xdg_cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "Successfully built sentence_transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, safetensors, ratelimiter, filetype, attr, semver, python-magic, pyarrow, py, mypy-extensions, emoji, charset-normalizer, typing-inspect, retry, pylance, marshmallow, unstructured, langsmith, lancedb, huggingface-hub, dataclasses-json, transformers, langchain, sentence_transformers\n",
      "\u001b[33m  WARNING: The script filetype is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script pysemver is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script normalizer is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script unstructured-ingest is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script langsmith is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script transformers-cli is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script langchain-server is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 13.0.0 which is incompatible.\n",
      "tensorflow 2.12.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed attr-0.3.2 charset-normalizer-2.0.12 dataclasses-json-0.5.14 emoji-2.8.0 filetype-1.2.0 huggingface-hub-0.16.4 lancedb-0.2.2 langchain-0.0.275 langsmith-0.0.27 marshmallow-3.20.1 mypy-extensions-1.0.0 py-1.11.0 pyarrow-13.0.0 pylance-0.6.5 python-magic-0.4.27 ratelimiter-1.2.0.post0 retry-0.9.2 safetensors-0.3.3 semver-3.0.1 sentence_transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.32.1 typing-inspect-0.9.0 unstructured-0.10.8\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain sentence_transformers lancedb unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ac58f3c",
   "metadata": {
    "cellId": "503n864wu3akn1mjo318yj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s][nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.62s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "import langchain.document_loaders\n",
    "\n",
    "source_dir = \"/home/jupyter/mnt/s3/mclass/text\"\n",
    "\n",
    "loader = langchain.document_loaders.DirectoryLoader(source_dir,glob=\"*.txt\",show_progress=True,recursive=True)\n",
    "splitter = langchain.text_splitter.RecursiveCharacterTextSplitter(chunk_size=512,chunk_overlap=50)\n",
    "fragments = splitter.create_documents([ x.page_content for x in loader.load()])\n",
    "len(fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81b723c0",
   "metadata": {
    "cellId": "lnsg67kshqfp494yccul07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = langchain.embeddings.HuggingFaceEmbeddings(model_name=\"distiluse-base-multilingual-cased-v1\")\n",
    "sample_vec = embeddings.embed_query(\"Hello, world!\")\n",
    "len(sample_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b91dfd9",
   "metadata": {
    "cellId": "5tmslotcscignkmh50g49p"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import LanceDB\n",
    "import lancedb\n",
    "\n",
    "db_dir = \"../store\"\n",
    "\n",
    "db = lancedb.connect(db_dir)\n",
    "table = db.create_table(\n",
    "    \"vector_index\",\n",
    "    data=[\n",
    "        {\n",
    "            \"vector\": embeddings.embed_query(\"Hello World\"),\n",
    "            \"text\": \"Hello World\",\n",
    "            \"id\": \"1\",\n",
    "        }\n",
    "    ],\n",
    "    mode=\"overwrite\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dad1026",
   "metadata": {
    "cellId": "j0bkb4g6igstk2umstio2j"
   },
   "outputs": [],
   "source": [
    "db = LanceDB.from_documents(fragments, embeddings, connection=table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdb51d8a",
   "metadata": {
    "cellId": "fdty939nkuf433bv37l2cs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "облачные технологии и после того когда Я прослушала конференция записала около 7 вопросов И придя на чехлом я спросила Вопрос уже как мы идем в облака Не нужны ли нам облачные технологии а как мы идем в облака в каких проектах мы можем использовать Гибридное частное облако надо какие сервисы есть сейчас В теха Решениях которые на рынке на рынке не так много решений и После этого когда Родились эти вопросы как мы идем в облака совершенно по другому заработали технологические команды и Начали предлагать и\n",
      "чтобы кибербезопасность Не упала в обморок и не написала отрицательное заключение мы использовали гибридное облако\n",
      "технологические команды и Начали предлагать и отвечать где какие сервисы и какие возможности сдаст нам облака 2 разных совершенно вопроса нужны ли нам облака нет не нужны А вопрос как мы будем использовать эти сервисы дальше была обыкновенная табличка в несколько компаний попали А в шорт лист как сделать выбор и абсолют банк сделал выбор в пользу яндекс облака Я вам расскажу я вам рассказываю как сео человек не имеющий техническое образование Какой вау эффект произвел на меня технологический комитет веду я\n",
      "запускаем ежегодно более 100 проектов Все это не возможно на собственных мощностях поэтому в прошлом году мы гибридизировали наши Структуру добавят к нашим собственным 4 дата центром Предложение от публичных облачных платформ И это то о чем я хочу поговорить сегодня о том как же началась дорога магнит в облака и к чему она привела В 4 квартале 21 года магнит принял стратегию клауд ферст официально заявив о том что наше развитие неразрывно связано с предложениями публичных облачных платформ Мы изначально\n"
     ]
    }
   ],
   "source": [
    "q=\"Что такое гибридные облака?\"\n",
    "\n",
    "res = db.similarity_search(q)\n",
    "for x in res:\n",
    "    print(x.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "431f115d",
   "metadata": {
    "cellId": "94wo2w5zglg0oyuubdoqlzc"
   },
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "res = retriever.get_relevant_documents(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7071b05a",
   "metadata": {
    "cellId": "j17m1mbp5hgxbgxvx0xnz"
   },
   "outputs": [],
   "source": [
    "from typing import Any, List, Mapping, Optional\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "import requests\n",
    "\n",
    "class YandexLLM(langchain.llms.base.LLM):\n",
    "    iam_token: str\n",
    "    folder_id: str\n",
    "    max_tokens : int = 1500\n",
    "    temperature : float = 1\n",
    "    instruction_text : str = None\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"yagpt\"\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "    ) -> str:\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "        req = {\n",
    "          \"model\": \"general\",\n",
    "          \"instruction_text\": self.instruction_text,\n",
    "          \"request_text\": prompt,\n",
    "          \"generation_options\": {\n",
    "            \"max_tokens\": self.max_tokens,\n",
    "            \"temperature\": self.temperature\n",
    "          }\n",
    "        }\n",
    "        res = requests.post(\"https://llm.api.cloud.yandex.net/llm/v1alpha/instruct\",\n",
    "          headers=\n",
    "            { \"Authorization\" : f\"Bearer {self.iam_token}\",\n",
    "              \"x-folder-id\" : self.folder_id }, json=req).json()\n",
    "        return res['result']['alternatives'][0]['text']\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {\"max_tokens\": self.max_tokens, \"temperature\" : self.temperature }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2683c706",
   "metadata": {
    "cellId": "17hb5txavf5iiscbggvvjg"
   },
   "outputs": [],
   "source": [
    "iam = \"t1.9euelZqZlZqUyY_HiouXk8jMnI2di-3rnpWalpOXl5iQzJqTyZeVzJaRl5vl8_cAHUxY-e9qTyJY_N3z90BLSVj572pPIlj8zef1656VmonOm4zHjMyVlc-Mj5ibjpGS7_zF656VmonOm4zHjMyVlc-Mj5ibjpGS.Xw3IuhSfz1C1IPfjsFChbbQ429A7X33S0Ip5y6X0le1ceV2uL0r2xTR2fb8MI1ZveYZQTe8Lz9rzcGt1Imx2Cw\"\n",
    "\n",
    "instructions = \"\"\"\n",
    "Представь себе, что ты работник техподдержки яндекс-облака. Твоя задача - подробно отвечать на все вопросы.\"\"\"\n",
    "\n",
    "llm = YandexLLM(iam_token=iam, folder_id=\"b1gbicod0scglhd49qs0\",\n",
    "                instruction_text = instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c85faf08",
   "metadata": {
    "cellId": "4ek9wo0my135q1p79ismqh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Добрый день! \\n\\nЕсли вам нужен `IAM-токен` для доступа к API Яндекс.Облака, вы можете запросить его в любом из наших продуктов и приложений. Список доступных продуктов и API доступен на странице https://tech.yandex.ru/cloud. В зависимости от продукта или API, вам понадобится `API-ключ` или `IAM-роли`, которые вы также можете получить через API. Если вы хотите узнать больше о продуктах или API Яндекс.Облако, пожалуйста, посмотрите на страницу https://www.ybxmission.com/.\\n\\nВы также можете подать заявку на это на [очередь операционных задач](https://cloud.yandex.ru/).'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Как получить iam-токен?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "279605c9",
   "metadata": {
    "cellId": "77y4w5s6seg08g1utincn7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Гибридные облака — это комбинация нескольких типов облаков, которые объединяются для улучшения безопасности и эффективности. То есть, в гибридном облаке используются как публичные, так и частные сценарии. Публичным облаком называют коммерческие облака, таких как Google Cloud, Amazon Web Services.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We prepare and run a custom Stuff chain with reordered docs as context.\n",
    "\n",
    "# Override prompts\n",
    "document_prompt = langchain.prompts.PromptTemplate(\n",
    "    input_variables=[\"page_content\"], template=\"{page_content}\"\n",
    ")\n",
    "document_variable_name = \"context\"\n",
    "stuff_prompt_override = \"\"\"Пожалуйста, посмотри на текст ниже и ответь на вопрос, используя информацию из этого текста.\n",
    "Текст:\n",
    "-----\n",
    "{context}\n",
    "-----\n",
    "Вопрос:\n",
    "{query}\"\"\"\n",
    "prompt = langchain.prompts.PromptTemplate(\n",
    "    template=stuff_prompt_override, input_variables=[\"context\", \"query\"]\n",
    ")\n",
    "\n",
    "# Instantiate the chain\n",
    "llm_chain = langchain.chains.LLMChain(llm=llm, prompt=prompt)\n",
    "chain = langchain.chains.StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_prompt=document_prompt,\n",
    "    document_variable_name=document_variable_name,\n",
    ")\n",
    "chain.run(input_documents=res, query=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cae1c86",
   "metadata": {
    "cellId": "dhzsgivm5s9mpky1db082"
   },
   "outputs": [],
   "source": [
    "from langchain.document_transformers import LongContextReorder\n",
    "reorderer = LongContextReorder()\n",
    "\n",
    "def answer(query,reorder=True):\n",
    "  results = retriever.get_relevant_documents(query)\n",
    "  if reorder:\n",
    "    results = reorderer.transform_documents(results)\n",
    "  return chain.run(input_documents=results, query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffadb2f9",
   "metadata": {
    "cellId": "is1wpwxhw1inxmwsqvixqa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вкратце, облако больше, чем резервный центр обработки данных, серверы, процессоры и хранилища. Возможности облака основаны на технологической платформе и библиотеках контейнерного развертывания и можно использовать для автоматизации разработки пользовательских приложений, тестирования их, организации тотальной изоляции изменений и эксплуатации.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"Зачем нужно облако?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10cb1fa",
   "metadata": {
    "cellId": "4byevx8504hx6nicfe2hia"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "369d3e82-763a-4bcd-b5cc-0cfe14f13f53",
  "notebookPath": "VideoQABot/Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
